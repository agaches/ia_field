#!/bin/bash

# Configuration
OTO_URL="http://localhost:8080"
OTO_API_HOST="otoroshi-api.oto.tools"
# Utilisation des credentials de l'API Admin par d√©faut
ADMIN_API_ID="admin-api-apikey-id"
ADMIN_API_SECRET="admin-api-apikey-secret"

# Attente du d√©marrage d'Otoroshi
echo "‚è≥ Attente du d√©marrage d'Otoroshi..."
until curl -s -u "$ADMIN_API_ID:$ADMIN_API_SECRET" -H "Host: $OTO_API_HOST" "$OTO_URL/health" | grep -q "otoroshi"; do
  sleep 5
  echo "..."
done
echo "‚úÖ Otoroshi est pr√™t !"

# Attente suppl√©mentaire pour s'assurer que l'API est compl√®tement pr√™te
sleep 3

# 1. Cr√©ation de la Route (Proxy vers Ollama)
echo "üöÄ Cr√©ation de la route Ollama..."
ROUTE_RESPONSE=$(curl -s -w "\n%{http_code}" -X POST -u "$ADMIN_API_ID:$ADMIN_API_SECRET" \
  -H "Host: $OTO_API_HOST" \
  -H "Content-Type: application/json" \
  -d '{
    "id": "route_ollama_proxy",
    "name": "Ollama AI Proxy",
    "description": "Route pour acc√©der √† Ollama via Otoroshi",
    "enabled": true,
    "groups": ["default"],
    "frontend": {
      "domains": ["ollama.oto.tools"],
      "strip_path": false,
      "exact": false
    },
    "backend": {
      "targets": [
        {
          "hostname": "ollama",
          "port": 11434,
          "tls": false
        }
      ],
      "root": "/",
      "rewrite": false,
      "load_balancing": { "type": "RoundRobin" }
    },
    "plugins": [
      {
        "plugin": "cp:otoroshi.next.plugins.ApikeyCalls",
        "enabled": true,
        "config": {
          "validate": true
        }
      }
    ]
  }' \
  "$OTO_URL/api/routes")

HTTP_CODE=$(echo "$ROUTE_RESPONSE" | tail -n1)
ROUTE_BODY=$(echo "$ROUTE_RESPONSE" | sed '$d')
echo "$ROUTE_BODY"
echo "üìä HTTP Status: $HTTP_CODE"

# 2. Cr√©ation d'une API Key pour le client
echo -e "\nüîë Cr√©ation de l'API Key..."
APIKEY_RESPONSE=$(curl -s -w "\n%{http_code}" -X POST -u "$ADMIN_API_ID:$ADMIN_API_SECRET" \
  -H "Host: $OTO_API_HOST" \
  -H "Content-Type: application/json" \
  -d '{
    "clientId": "my-llm-client-id",
    "clientSecret": "my-llm-client-secret",
    "clientName": "LLM Client",
    "description": "API Key pour acc√©der √† Ollama",
    "authorizedGroup": "default",
    "authorizedEntities": ["route_ollama_proxy"],
    "enabled": true,
    "throttlingQuota": 10000000,
    "dailyQuota": 10000000,
    "monthlyQuota": 10000000
  }' \
  "$OTO_URL/api/apikeys")

HTTP_CODE=$(echo "$APIKEY_RESPONSE" | tail -n1)
APIKEY_BODY=$(echo "$APIKEY_RESPONSE" | sed '$d')
echo "$APIKEY_BODY"
echo "üìä HTTP Status: $HTTP_CODE"

# 3. V√©rification des routes cr√©√©es
echo -e "\nüîç V√©rification des routes..."
curl -s -u "$ADMIN_API_ID:$ADMIN_API_SECRET" \
  -H "Host: $OTO_API_HOST" \
  "$OTO_URL/api/routes" | jq '.[] | {id: .id, name: .name, domains: .frontend.domains, enabled: .enabled}'

# 4. V√©rification des API Keys cr√©√©es
echo -e "\nüîç V√©rification des API Keys..."
curl -s -u "$ADMIN_API_ID:$ADMIN_API_SECRET" \
  -H "Host: $OTO_API_HOST" \
  "$OTO_URL/api/apikeys" | jq '.[] | {clientId: .clientId, clientName: .clientName, authorizedEntities: .authorizedEntities, enabled: .enabled}'

echo -e "\n\nüéâ Setup Termin√© !"
echo ""
echo "‚úÖ Commande de test (avec headers Otoroshi) :"
echo "curl -H 'Otoroshi-Client-Id: my-llm-client-id' -H 'Otoroshi-Client-Secret: my-llm-client-secret' -H 'Host: ollama.oto.tools' http://localhost:8080/v1/models"
echo ""
echo "üìö Pour charger un mod√®le dans Ollama :"
echo "docker exec ollama ollama pull llama2"
echo ""
echo "üîß Pour tester directement Ollama (sans Otoroshi) :"
echo "curl http://localhost:11434/v1/models"
