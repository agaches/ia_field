# Phase 5 : Secure - S√©curit√© IA

## Vue d'ensemble

Les syst√®mes IA pr√©sentent des risques de s√©curit√© uniques au-del√† des menaces traditionnelles : prompt injection, data poisoning, model theft, et hallucinations. Cette phase structure la protection des actifs IA √† travers d√©couverte, protection et d√©tection.

## 1. D√©couvrir les risques de s√©curit√© IA

### OWASP Top 10 pour LLM (2025)

Le [OWASP Generative AI](https://genai.owasp.org/) documente les risques sp√©cifiques aux LLMs.

| Rang | Risque | Description | Impact | Mitigation principale |
|------|--------|-------------|--------|----------------------|
| **LLM01** | Prompt Injection | Manipulation du comportement via prompts malveillants | √âlev√© | Validation inputs, sandboxing, guardrails |
| **LLM02** | Insecure Output Handling | Traitement non s√©curis√© des outputs LLM | √âlev√© | Validation outputs, encoding, sanitization |
| **LLM03** | Training Data Poisoning | Injection de donn√©es malveillantes dans training | Moyen | Validation sources, data provenance, audits |
| **LLM04** | Model Denial of Service | Surcharge ressources via inputs co√ªteux | Moyen | Rate limiting, quotas, monitoring |
| **LLM05** | Supply Chain Vulnerabilities | D√©pendances non s√©curis√©es (mod√®les, datasets) | √âlev√© | V√©rification provenance, scanning vuln√©rabilit√©s |
| **LLM06** | Sensitive Information Disclosure | Fuite donn√©es sensibles via outputs/mod√®les | √âlev√© | DLP, anonymisation, filtering |
| **LLM07** | Insecure Plugin Design | Plugins tiers non s√©curis√©s | Moyen | Validation plugins, sandboxing, least privilege |
| **LLM08** | Excessive Agency | Permissions excessives pour agents IA | √âlev√© | Least privilege, human-in-the-loop, approval gates |
| **LLM09** | Overreliance | Confiance excessive sans validation | Moyen | Human validation, fact-checking, disclaimers |
| **LLM10** | Model Theft | Vol de mod√®les propri√©taires | Moyen | Contr√¥les d'acc√®s, watermarking, API rate limits |

### MITRE ATLAS - Adversarial Threat Landscape

Le [MITRE ATLAS](https://atlas.mitre.org/) cartographie les tactiques et techniques d'attaque IA.

**Phases d'attaque principales** :
1. **Reconnaissance** : D√©couverte architecture IA, mod√®les, donn√©es
2. **Resource Development** : Pr√©paration datasets adversariaux, outils
3. **Initial Access** : Exploitation vuln√©rabilit√©s, phishing
4. **Execution** : Prompt injection, model poisoning
5. **Persistence** : Backdoors dans mod√®les, acc√®s maintenu
6. **Exfiltration** : Vol mod√®les, datasets, propri√©t√© intellectuelle

### Matrice menaces IA et contre-mesures

| Menace | Vecteur d'attaque | Impact potentiel | Contre-mesures techniques | Contre-mesures organisationnelles |
|--------|------------------|------------------|---------------------------|----------------------------------|
| **Prompt Injection** | Inputs utilisateur malveillants | Ex√©cution commandes non autoris√©es | Input filtering, guardrails, sandboxing | Formation utilisateurs, monitoring |
| **Data Poisoning** | Manipulation datasets training | Mod√®le biais√©/compromis | Validation provenance, anomaly detection | Revue donn√©es, audits pipeline |
| **Model Extraction** | Requ√™tes API r√©p√©t√©es | Vol IP, r√©plication mod√®le | Rate limiting, watermarking, output obfuscation | Acc√®s restreint, contrats NDA |
| **Membership Inference** | Analyse outputs mod√®le | Fuite confidentialit√© training data | Differential privacy, output filtering | Anonymisation datasets, DLP |
| **Adversarial Examples** | Inputs craft√©s pour tromper mod√®le | D√©cisions incorrectes | Adversarial training, input sanitization | Human validation critique |
| **Backdoor Attacks** | Mod√®les/datasets compromis supply chain | Comportement malveillant cach√© | Model scanning, provenance verification | Fournisseurs valid√©s, audits |

## 2. Prot√©ger les ressources et donn√©es

### Architecture de s√©curit√© en profondeur

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               User / Application Layer               ‚îÇ
‚îÇ  - Authentication (MFA)                             ‚îÇ
‚îÇ  - Input validation & filtering                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  API Gateway Layer                   ‚îÇ
‚îÇ  - Rate limiting / Quotas                           ‚îÇ
‚îÇ  - Request/Response filtering                       ‚îÇ
‚îÇ  - WAF (Web Application Firewall)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Application / AI Service                ‚îÇ
‚îÇ  - Guardrails (content filtering)                   ‚îÇ
‚îÇ  - DLP (sensitive data detection)                   ‚îÇ
‚îÇ  - Prompt engineering (safety)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Model Layer                        ‚îÇ
‚îÇ  - Model access controls (IAM)                      ‚îÇ
‚îÇ  - Versioning & approval (gates)                    ‚îÇ
‚îÇ  - Watermarking (optional)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Data Layer                        ‚îÇ
‚îÇ  - Encryption at rest (KMS)                         ‚îÇ
‚îÇ  - Encryption in transit (TLS)                      ‚îÇ
‚îÇ  - Data classification & masking                    ‚îÇ
‚îÇ  - Access controls (IAM)                            ‚îÇ
‚îÇ  - Audit logging (immutable)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Infrastructure Layer                    ‚îÇ
‚îÇ  - Network isolation (VPC/VNet)                     ‚îÇ
‚îÇ  - Bastion access only                              ‚îÇ
‚îÇ  - Security groups / Firewalls                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Chiffrement des donn√©es IA

| Type de donn√©es | Chiffrement at rest | Chiffrement in transit | Chiffrement in use (optionnel) |
|-----------------|---------------------|------------------------|-------------------------------|
| **Training datasets** | KMS-encrypted storage | TLS 1.2+ | Confidential Computing (TEE) |
| **Models** | KMS-encrypted registry | TLS 1.2+ | Secure Enclaves |
| **Inference inputs/outputs** | Encrypted cache/logs | TLS 1.2+ | Ephemeral, PII masking |
| **Vector databases (RAG)** | Encrypted storage | TLS 1.2+ | Field-level encryption |

Voir [GLOSSARY.md](GLOSSARY.md) pour services de chiffrement (KMS) par cloud.

### IAM pour IA - Least Privilege

**Principe** : Accorder uniquement les permissions n√©cessaires pour chaque r√¥le.

**R√¥les et permissions recommand√©es** :

| R√¥le | Permissions | Justification |
|------|-------------|---------------|
| **Data Scientist** | Read datasets, Read/Write models (dev), Submit training jobs | D√©veloppement et exp√©rimentation |
| **ML Engineer** | Read datasets, Read/Write models (staging/prod), Deploy endpoints | D√©ploiement et op√©rations |
| **MLOps Engineer** | Manage infrastructure, Configure monitoring, Manage CI/CD | Infrastructure et automation |
| **Data Engineer** | Read/Write datasets, Manage data pipelines | Gestion donn√©es |
| **Business User** | Invoke inference endpoints (read-only) | Consommation pr√©dictions |
| **Auditor** | Read-only all resources, Read logs | Audit et conformit√© |

**Contr√¥les additionnels** :
- **MFA obligatoire** pour acc√®s console cloud
- **Temporary credentials** (STS, Workload Identity) vs static keys
- **Conditional access** : Restreindre par IP/VPN pour admin
- **Break-glass accounts** : Acc√®s urgence, logged et review√©

### DLP pour IA

**D√©tection donn√©es sensibles** :
- **PII** : Noms, emails, num√©ros t√©l√©phone, SSN, etc.
- **PHI** : Donn√©es sant√© (HIPAA)
- **PCI** : Donn√©es cartes bancaires
- **Secrets** : API keys, credentials, tokens

**Points de contr√¥le DLP** :
1. **Inputs utilisateur** : Bloquer prompts avec PII
2. **Training datasets** : Scanner et anonymiser avant usage
3. **Model outputs** : Filtrer PII dans r√©ponses LLM
4. **Logs et monitoring** : Redact donn√©es sensibles

**Outils DLP par cloud** : Voir [GLOSSARY.md](GLOSSARY.md)

### Guardrails et Content Filtering

**Guardrails GenAI** :
- **Input guardrails** : Bloquer prompts toxiques, jailbreak attempts
- **Output guardrails** : Filtrer contenu inappropri√©, hallucinations
- **Topical guardrails** : Restreindre sujets autoris√©s (ex: pas de conseil m√©dical)

**Services cloud-native** :
- **AWS** : Bedrock Guardrails
- **GCP** : Vertex AI safety filters
- **Azure** : Azure OpenAI Content Filters

**Configuration type** :
```
Content Filter Policy:
  - Hate speech: Block (threshold: medium)
  - Violence: Block (threshold: high)
  - Sexual content: Block (threshold: low)
  - Self-harm: Block (threshold: low)
  - PII detection: Block & log
  - Prompt injection patterns: Block
```

### Flux de donn√©es s√©curis√© (exemple RAG)

```
User Input
    ‚Üì
[Input Validation] ‚Üí Block malicious patterns
    ‚Üì
[DLP Check] ‚Üí Redact/Block PII
    ‚Üì
[Guardrails - Input] ‚Üí Block inappropriate content
    ‚Üì
Vector DB Query (encrypted TLS)
    ‚Üì
[RAG Context] ‚Üí Retrieved from encrypted storage
    ‚Üì
LLM Inference (authenticated API)
    ‚Üì
[Guardrails - Output] ‚Üí Filter unsafe content
    ‚Üì
[DLP Check] ‚Üí Redact PII in response
    ‚Üì
[Output Validation] ‚Üí Verify format & safety
    ‚Üì
User Response (logged, encrypted at rest)
```

## 3. D√©tecter les menaces

### Monitoring de s√©curit√© pour IA

**M√©triques de s√©curit√© √† surveiller** :

| M√©trique | Seuil d'alerte | Fr√©quence | Action |
|----------|---------------|-----------|--------|
| **Tentatives prompt injection** | > 10/heure | Temps r√©el | Bloquer IP, investigate |
| **Taux de blocage guardrails** | > 15% requests | Quotidien | Revue patterns, ajuster filtres |
| **Acc√®s non autoris√© mod√®les** | > 0 | Temps r√©el | Bloquer acc√®s, alert security |
| **Anomalies dans outputs** | Drift > 20% | Hebdo | Investigate data poisoning |
| **Volume inference inhabituel** | > 3x baseline | Temps r√©el | Check DoS attack |
| **Fuite PII d√©tect√©e** | > 0 | Temps r√©el | Block, investigate, incident P0 |
| **√âchecs authentication** | > 5/minute | Temps r√©el | Rate limit, block IP |
| **Modifications non approuv√©es** | > 0 | Temps r√©el | Rollback, investigate |

### Logging et audit pour IA

**Logs √† collecter (immutables)** :
- **Access logs** : Qui acc√®de √† quoi, quand
- **Inference logs** : Inputs/outputs (avec DLP redaction)
- **Training logs** : Datasets utilis√©s, hyperparam√®tres, r√©sultats
- **Deployment logs** : Changements mod√®les, configurations
- **Security events** : Tentatives injection, blocages, violations

**R√©tention recommand√©e** :
- Security events : 1 an minimum (conformit√© GDPR/CCPA)
- Inference logs : 90 jours (hot) + archivage 1 an (cold)
- Audit logs : 7 ans (r√©glementations sectorielles)

Voir [GLOSSARY.md](GLOSSARY.md) pour services de logging par cloud.

### Incident Response pour IA

**Playbooks sp√©cifiques IA** :

**1. Prompt Injection D√©tect√©** :
- [ ] Bloquer IP source
- [ ] Analyser pattern d'attaque
- [ ] V√©rifier autres tentatives similaires
- [ ] Renforcer guardrails si n√©cessaire
- [ ] Documenter et communiquer

**2. Data Leak / PII Exposure** :
- [ ] Incident P0 - Escalade imm√©diate
- [ ] Identifier port√©e : Combien de records expos√©s
- [ ] Notification l√©gal/privacy officer < 2h
- [ ] Bloquer endpoint si n√©cessaire
- [ ] Notification utilisateurs affect√©s (GDPR 72h)
- [ ] Root cause analysis et rem√©diation

**3. Model Drift Suspect (Poisoning)** :
- [ ] Rollback vers version pr√©c√©dente
- [ ] Investiguer datasets r√©cents
- [ ] V√©rifier provenance et int√©grit√©
- [ ] Retrain si n√©cessaire avec donn√©es valid√©es
- [ ] Renforcer validation pipeline

**4. DoS Attack sur Inference API** :
- [ ] Activer rate limiting agressif
- [ ] Bloquer IPs malveillantes
- [ ] Scale infrastructure si n√©cessaire
- [ ] Investigate origine attaque
- [ ] Renforcer WAF rules

### Outils de d√©tection

**SIEM pour IA** :
- Centraliser logs multi-sources (application, cloud, mod√®les)
- Corr√©lation √©v√©nements pour d√©tection patterns
- Alerting automatique sur seuils
- Voir [GLOSSARY.md](GLOSSARY.md) pour outils SIEM

**Anomaly Detection** :
- D√©tection comportements inhabituels dans inference patterns
- Monitoring drift mod√®le (voir [Phase Manage](06-manage.md))
- Baseline comportement normal, alerte sur d√©viations

**Threat Intelligence** :
- Abonnement feeds de menaces IA (MITRE ATLAS, OWASP)
- Partage incidents secteur (ISAC)
- Veille CVE mod√®les et frameworks

### Pentesting et Red Teaming pour IA

**Tests de s√©curit√© sp√©cifiques IA** :
- **Prompt injection testing** : Tentatives jailbreak, manipulation
- **Model extraction** : Tentatives de vol via API
- **Data inference** : Tentatives de d√©couvrir training data
- **Adversarial examples** : Inputs craft√©s pour tromper mod√®le

**Fr√©quence recommand√©e** :
- Pentest manuel : Annuel ou avant d√©ploiement majeur
- Automated scanning : Continu (int√©gr√© CI/CD)
- Red team exercise : Semestriel (entreprises matures)

## Checklist Secure

### üöÄ Startup
- [ ] Activer chiffrement donn√©es (at rest + in transit)
- [ ] Configurer IAM least privilege
- [ ] Activer guardrails et content filtering
- [ ] Mettre en place DLP basique (PII detection)

### üè¢ Enterprise
- [ ] Impl√©menter architecture s√©curit√© en profondeur (toutes couches)
- [ ] D√©ployer DLP avanc√© (inputs, outputs, logs)
- [ ] Configurer monitoring s√©curit√© temps r√©el avec alertes
- [ ] √âtablir incident response playbooks pour IA
- [ ] Activer audit logging immutable (r√©tention conforme)
- [ ] Conduire pentesting et red teaming IA (annuel)
- [ ] Int√©grer threat intelligence IA

## Prochaine √©tape

‚Üí [Phase 6 : Manage](06-manage.md) - G√©rer l'IA
