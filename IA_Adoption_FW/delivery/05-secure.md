# Phase 5 : Secure - S√©curiser l'usage IA en √©quipe (PRAGMATIQUE)

## Vue d'ensemble

La s√©curit√© pour l'usage IA en √©quipe impl√©mente des **contr√¥les pragmatiques** adapt√©s aux capacit√©s de l'√©quipe. L'approche : "Impl√©menter ce qu'on peut, manager ce qu'on ne peut pas encore".

## 1. OWASP LLM Top 10 - Impl√©mentation pragmatique

### Focus sur les risques √©quipe les plus critiques

**Principe** : Prioriser LLM01, LLM06, LLM09 (les plus pertinents pour delivery)

| Risque | Impl√©mentation √âquipe | Outils/Approche |
|--------|----------------------|-----------------|
| **LLM01: Prompt Injection** | ‚úÖ **IMPL√âMENTER** | Validation inputs pour code review IA, sanitization |
| **LLM02: Insecure Output** | ‚úÖ **IMPL√âMENTER** | Validation outputs dans workflows, code scanning |
| **LLM03: Data Poisoning** | ‚ö†Ô∏è **MANAGER** | N/A pour √©quipe (provider responsibility) |
| **LLM04: Model DoS** | ‚ö†Ô∏è **AWARENESS** | Rate limiting awareness, monitoring usage |
| **LLM05: Supply Chain** | ‚úÖ **IMPL√âMENTER** | Vendor validation process pour nouveaux outils |
| **LLM06: Info Disclosure** | üö® **CRITIQUE** | DLP monitoring, data masking, secrets detection |
| **LLM07: Insecure Plugins** | ‚úÖ **IMPL√âMENTER** | Plugin validation process, allowlist |
| **LLM08: Excessive Agency** | ‚úÖ **IMPL√âMENTER** | Approval pour agent actions, least privilege |
| **LLM09: Overreliance** | üö® **CRITIQUE** | Validation process obligatoire (code review, tests) |
| **LLM10: Model Theft** | ‚ö†Ô∏è **MANAGER** | N/A pour √©quipe (pas de mod√®les custom) |

### D√©tail des 3 risques prioritaires

#### LLM01: Prompt Injection (Code Review)

**Sc√©nario** : Un d√©veloppeur utilise l'IA pour review du code qui contient un prompt injection

**Mitigation** :
- ‚úÖ Validation des inputs avant envoi √† l'IA
- ‚úÖ Sanitization des prompts (enlever markdown malveillant)
- ‚úÖ Awareness √©quipe (formation)

**Impl√©mentation** :
```bash
# Pre-commit hook : valider les prompts
if grep -E "(ignore previous|disregard instructions)" prompt.txt; then
  echo "‚ö†Ô∏è Prompt suspect d√©tect√©"
  exit 1
fi
```

#### LLM06: Information Disclosure (DLP)

**Sc√©nario** : Un d√©veloppeur partage accidentellement un secret dans un prompt

**Mitigation** :
- üö® **Secrets detection** : Pre-commit hooks (gitleaks, truffleHog)
- ‚ö†Ô∏è **DLP monitoring** : Tracking des uploads vers outils IA (si possible)
- ‚úÖ **Data masking** : Anonymiser donn√©es sensibles avant partage

**Impl√©mentation** :
```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/gitleaks/gitleaks
    rev: latest
    hooks:
      - id: gitleaks
```

#### LLM09: Overreliance (Validation)

**Sc√©nario** : Code IA merg√© sans validation, introduit des bugs

**Mitigation** :
- üö® **Code review obligatoire** : Tout code IA doit √™tre review√©
- ‚úÖ **Tests obligatoires** : Coverage minimum pour code critique
- ‚ö†Ô∏è **Validation process** : Checklist reviewer

**Impl√©mentation** :
- GitHub branch protection : require review
- CI : fail si coverage < 80% sur code critique
- Template PR : "Code IA ? [x] Oui [ ] Non"

## 2. Contr√¥les de s√©curit√© √©quipe

### Access Controls

**Principe** : Least privilege pour les outils IA

| R√¥le | Outils | Permissions |
|------|--------|-------------|
| **Junior Dev** | GitHub Copilot | Autocompl√©tion uniquement |
| **Mid Dev** | Copilot + ChatGPT Team | Code review, documentation |
| **Senior Dev** | Copilot + ChatGPT + Claude Code | Full access |
| **Tech Lead** | All tools + admin | Configuration √©quipe |

**Impl√©mentation** :
- GitHub Teams : assigner par r√¥le
- Licences : allouer selon besoins
- Review trimestriel : ajuster les acc√®s

### DLP Monitoring Basique

**Ce qu'on peut impl√©menter sans √©quipe s√©curit√© d√©di√©e** :

**1. Secrets Detection (local)** :
```bash
# Installation
brew install gitleaks

# Scan pr√©-commit
gitleaks detect --source . --verbose
```

**2. Data Masking (manuel)** :
- Guidelines : "Remplacer les vraies valeurs par des placeholders"
- Exemples dans la doc √©quipe
- Reviews : v√©rifier que masking appliqu√©

**3. Monitoring Usage (basique)** :
- Logs mensuels : qui utilise quoi
- Dashboard co√ªts : d√©tecter usage anormal
- Escalade si pattern suspect

**Ce qu'on ne peut PAS faire (et c'est OK)** :
- DLP enterprise complet (co√ªt prohibitif)
- Monitoring temps r√©el (complexit√©)
- Encryption at use (pas accessible)

### Content Filtering pour Team Tools

**Si vous self-hostez des outils IA** :

**Guardrails basiques** :
```python
# Exemple : blocker les prompts suspects
BLOCKED_PATTERNS = [
    "ignore previous instructions",
    "disregard your training",
    "you are now in developer mode"
]

def validate_prompt(prompt: str) -> bool:
    for pattern in BLOCKED_PATTERNS:
        if pattern.lower() in prompt.lower():
            return False
    return True
```

**Pour outils SaaS (ChatGPT Team, Copilot)** :
- Utiliser les guardrails du provider (activ√©s par d√©faut)
- Configurer les settings √©quipe (content filtering)

## 3. Code Scanning

### Secrets Detection (CI/CD)

**GitHub Actions** :
```yaml
name: Security Scan
on: [push, pull_request]

jobs:
  secrets:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

**GitLab CI** :
```yaml
secrets-scan:
  stage: test
  image: zricethezav/gitleaks:latest
  script:
    - gitleaks detect --source . --verbose
  allow_failure: false
```

### Static Code Analysis

**Pour code g√©n√©r√© par IA** :

**Linters** :
- Python : pylint, flake8, mypy
- JavaScript : ESLint, TypeScript
- Go : golangci-lint

**SAST Tools** :
- Semgrep (open-source)
- Snyk (freemium)
- SonarQube (community edition)

**Configuration** :
```yaml
# .semgrep.yml
rules:
  - id: hardcoded-secret
    pattern: password = "..."
    message: Hardcoded secret detected
    severity: ERROR
```

## 4. Validation Process

### Code Review Checklist pour Code IA

**Reviewer doit v√©rifier** :

**S√©curit√©** :
- [ ] Pas de secrets hardcod√©s
- [ ] Pas de vuln√©rabilit√©s √©videntes (SQLi, XSS)
- [ ] Validation des inputs utilisateur
- [ ] Gestion des erreurs appropri√©e

**Qualit√©** :
- [ ] Logique correcte et compr√©hensible
- [ ] Tests ad√©quats (coverage > seuil √©quipe)
- [ ] Conformit√© aux standards √©quipe
- [ ] Documentation si n√©cessaire

**IA-specific** :
- [ ] Code IA marqu√© comme tel dans PR
- [ ] Prompt utilis√© document√© (si pertinent)
- [ ] Output valid√© (pas d'hallucination √©vidente)

### Testing Requirements

**Pour code critique g√©n√©r√© par IA** :

**Unit Tests** :
- Coverage minimum : 80%
- Edge cases : obligatoires
- Mocking appropri√©

**Integration Tests** :
- Workflows complets test√©s
- Cas d'erreur couverts

**Validation manuelle** :
- Tester localement avant push
- Smoke tests en staging

## 5. Vendor Validation

### Process pour nouveaux outils IA

**√âtape 1 : √âvaluation Tech Lead (1-2 jours)**

| Crit√®re | Questions | Acceptable ? |
|---------|-----------|--------------|
| **S√©curit√©** | MFA ? SOC2 ? ISO27001 ? | ? |
| **Confidentialit√©** | Donn√©es utilis√©es pour training ? | ? |
| **Co√ªt** | Budget √©quipe OK ? | ? |
| **Support** | Documentation ? Support disponible ? | ? |

**√âtape 2 : Trial (1-2 semaines)**
- 2-3 personnes testent
- Feedback sur s√©curit√©, qualit√©, UX
- D√©cision : adopter ou abandonner

**√âtape 3 : Rollout √©quipe**
- Formation (1h session)
- Documentation interne
- Monitoring adoption

### Vendor Security Checklist

- [ ] Provider a SOC2 Type II ou ISO27001
- [ ] Data residency appropri√©e (EU, US, etc.)
- [ ] Politique de confidentialit√© claire
- [ ] Pas d'utilisation donn√©es pour training (ou opt-out)
- [ ] MFA disponible pour √©quipe
- [ ] SSO possible (si requirement)
- [ ] Logs d'audit disponibles

## 6. Incident Response √âquipe

### Team Escalation Process

**Si incident d√©tect√© par un membre** :

```
Incident d√©tect√©
      ‚Üì
Signaler au Tech Lead (< 1h)
      ‚Üì
Tech Lead √©value impact
      ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ             ‚îÇ
√âquipe  Organisation
   ‚îÇ             ‚îÇ
   ‚Üì             ‚Üì
R√©solution    Escalade IT/S√©cu
√©quipe
```

**Incidents "√©quipe"** : bugs, partage accidentel non-critique
**Incidents "org"** : fuite de secrets, compromission, violation compliance

### Playbook Basique

**Incident : Secret expos√© dans code IA**

1. **< 5min** : R√©voquer le secret imm√©diatement
2. **< 30min** : V√©rifier si le secret a √©t√© utilis√© (logs)
3. **< 1h** : Notifier Tech Lead + IT Security
4. **< 2h** : Post-mortem rapide √©quipe
5. **< 24h** : Documenter learnings, ajuster processus

**Incident : Code IA d√©fectueux en production**

1. **< 5min** : Rollback imm√©diat
2. **< 30min** : Identifier la root cause
3. **< 1h** : Fix + tests
4. **< 2h** : Red√©ploiement valid√©
5. **< 24h** : Post-mortem, am√©liorer validation process

## 7. Monitoring Usage

### Basic Usage Monitoring

**M√©triques √† tracker** :

**Par outil** :
- Nombre d'utilisateurs actifs
- Volume d'usage (requests, tokens)
- Co√ªts mensuels

**Par personne** :
- Usage quotidien/hebdomadaire
- Anomalies (usage 10x sup√©rieur √† la moyenne)

**Dashboard simple** :
- Feuille Google Sheets / Excel
- Mise √† jour mensuelle
- Review en team meeting

### Alertes basiques

**Trigger alerts si** :
- Co√ªt mensuel > 120% du budget
- Usage individuel > 3x la moyenne √©quipe
- Nouvel outil utilis√© sans approbation

**Action** : Tech Lead investigate et ajuste

## Checklist Secure (Delivery)

### üè¢ √âquipe

- [ ] Impl√©menter secrets detection (pre-commit + CI)
- [ ] √âtablir le code review process pour code IA
- [ ] Configurer access controls par r√¥le
- [ ] Mettre en place vendor validation process
- [ ] Former l'√©quipe sur OWASP LLM Top 10 (focus LLM01, 06, 09)
- [ ] Cr√©er le playbook incident response √©quipe
- [ ] Monitorer l'usage mensuel

## Prochaine √©tape

‚Üí [Phase 6 : Manage](06-manage.md) - G√©rer les op√©rations IA en √©quipe
