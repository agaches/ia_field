# Phase 5 : Secure - SÃ©curiser votre usage personnel de l'IA (AWARENESS)

## Vue d'ensemble

La sÃ©curitÃ© pour l'usage individuel de l'IA se concentre sur la **sensibilisation aux risques** et l'application de **bonnes pratiques personnelles**. Vous Ãªtes responsable de protÃ©ger vos comptes, vos donnÃ©es et de valider les outputs.

## 1. OWASP LLM Top 10 - Awareness

### Comprendre les risques principaux

| Risque | Ce que c'est | Ce que VOUS devez faire |
|--------|--------------|-------------------------|
| **LLM01: Prompt Injection** | Quelqu'un peut manipuler le LLM via un prompt malveillant | âš ï¸ **Awareness** : Sachez que c'est possible, soyez critique |
| **LLM02: Insecure Output** | Le LLM gÃ©nÃ¨re du contenu dangereux (XSS, code malveillant) | âš ï¸ **Validation** : Toujours vÃ©rifier avant d'utiliser |
| **LLM03: Data Poisoning** | Les donnÃ©es d'entraÃ®nement sont corrompues | â„¹ï¸ **N/A** : ResponsabilitÃ© du provider (ChatGPT, etc.) |
| **LLM04: Model DoS** | Attaque par dÃ©ni de service sur le modÃ¨le | â„¹ï¸ **N/A** : Les providers SaaS ont des rate limits |
| **LLM05: Supply Chain** | VulnÃ©rabilitÃ©s dans la chaÃ®ne d'approvisionnement | â„¹ï¸ **N/A** : ResponsabilitÃ© du provider |
| **LLM06: Info Disclosure** | â— **CRITIQUE** : Fuite de donnÃ©es sensibles | ğŸš¨ **NE JAMAIS** partager de donnÃ©es sensibles dans prompts |
| **LLM07: Insecure Plugins** | Plugins tiers non sÃ©curisÃ©s | âš ï¸ **Validation** : N'installer que des plugins approuvÃ©s |
| **LLM08: Excessive Agency** | Le LLM a trop de permissions | â„¹ï¸ **N/A** : Usage personnel, pas d'agents autonomes |
| **LLM09: Overreliance** | â— **IMPORTANT** : Confiance aveugle dans les outputs | ğŸš¨ **TOUJOURS** valider et vÃ©rifier les outputs |
| **LLM10: Model Theft** | Vol du modÃ¨le | â„¹ï¸ **N/A** : ResponsabilitÃ© du provider |

### Focus critique pour vous

**LLM06 - Information Disclosure** :
- âŒ **Ne JAMAIS** mettre : credentials, API keys, passwords
- âŒ **Ne JAMAIS** mettre : donnÃ©es clients, PII de collÃ¨gues
- âŒ **Ne JAMAIS** mettre : propriÃ©tÃ© intellectuelle confidentielle
- âœ… **OK de mettre** : donnÃ©es publiques, vos notes personnelles

**LLM09 - Overreliance** :
- âš ï¸ Le LLM peut se tromper (hallucinations)
- âš ï¸ Le LLM peut gÃ©nÃ©rer du code avec bugs
- âš ï¸ Le LLM peut donner des conseils incorrects
- âœ… **TOUJOURS** : vÃ©rifier, tester, valider

## 2. Bonnes pratiques de sÃ©curitÃ© personnelles

### ContrÃ´les essentiels

**1. Multi-Factor Authentication (MFA)** ğŸ”
- âœ… Activer MFA sur TOUS vos comptes IA
- âœ… Utiliser une app authenticator (pas SMS)
- âœ… Sauvegarder les recovery codes

**2. Gestion des mots de passe** ğŸ”‘
- âœ… Utiliser un gestionnaire de mots de passe (1Password, Bitwarden, etc.)
- âœ… Mots de passe uniques pour chaque compte
- âŒ Jamais de mot de passe dans les prompts

**3. Classification des donnÃ©es** ğŸ“Š
Avant chaque prompt, demandez-vous :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Est-ce public ?             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚       â”‚
  OUI       NON
    â”‚       â”‚
    â†“       â†“
  âœ… OK    âŒ NE PAS PARTAGER
```

**4. Pas de secrets dans les prompts** ğŸ”’
- âŒ API keys â†’ Utiliser variables d'environnement
- âŒ Passwords â†’ Utiliser gestionnaire
- âŒ Tokens â†’ Utiliser configuration locale
- âœ… Demander Ã  l'IA comment structurer sans les valeurs rÃ©elles

### Checklist avant chaque utilisation

- [ ] Mon compte a-t-il MFA activÃ© ?
- [ ] Vais-je partager des donnÃ©es sensibles dans ce prompt ?
- [ ] Ai-je vÃ©rifiÃ© que cet outil est approuvÃ© par l'entreprise ?
- [ ] Vais-je valider l'output avant de l'utiliser ?

## 3. Guardrails des providers

### Protection par dÃ©faut (SaaS)

Les outils que vous utilisez (ChatGPT, Copilot, Claude) ont dÃ©jÃ  des protections intÃ©grÃ©es :

**Content Filtering** :
- Refus de gÃ©nÃ©rer du contenu illÃ©gal/dangereux
- DÃ©tection de tentatives de jailbreak
- Filtrage de contenu inappropriÃ©

**Data Protection (selon provider)** :
- ChatGPT Enterprise : donnÃ©es non utilisÃ©es pour entraÃ®nement
- GitHub Copilot for Business : code non partagÃ©
- VÃ©rifier les settings de confidentialitÃ©

### VÃ©rifier les paramÃ¨tres de votre compte

**Pour ChatGPT** :
1. Settings â†’ Data Controls
2. DÃ©sactiver "Improve model" si option disponible
3. Activer "Chat History & Training" selon prÃ©fÃ©rence

**Pour GitHub Copilot** :
1. Settings â†’ Copilot
2. VÃ©rifier "Public code suggestions" selon besoins
3. Activer "Copilot Chat" si disponible

## 4. DLP - Data Loss Prevention (Awareness)

### Qu'est-ce que le DLP ?

**DLP** = Outils qui empÃªchent la fuite de donnÃ©es sensibles

**Ce que l'IT peut faire** :
- Monitoring des uploads vers outils IA
- Blocage automatique si secrets dÃ©tectÃ©s
- Alertes si patterns suspects

**Ce que VOUS devez faire** :
- ÃŠtre conscient que vos actions peuvent Ãªtre monitorÃ©es
- Respecter les politiques mÃªme si pas de DLP technique
- Signaler si vous voyez des collÃ¨gues partager des donnÃ©es sensibles

### Auto-DLP : Votre responsabilitÃ©

**RÃ¨gle simple** : Si vous hÃ©sitez, ne partagez pas.

Questions Ã  vous poser :
1. Est-ce que je montrerais ceci sur Twitter ?
   - OUI â†’ OK
   - NON â†’ Ne pas partager
2. Est-ce que mon manager approuverait ?
   - OUI â†’ OK
   - NON â†’ Demander permission
3. Est-ce que cela pourrait nuire Ã  l'entreprise si publiÃ© ?
   - OUI â†’ NE PAS PARTAGER
   - NON â†’ OK

## 5. Incident Response

### Si vous commettez une erreur

**ScÃ©nario** : J'ai accidentellement partagÃ© un API key dans ChatGPT

**Actions immÃ©diates** :
1. â±ï¸ **ImmÃ©diatement** : RÃ©voquer/changer le secret
2. ğŸ“ **< 1h** : Ouvrir un ticket IT (incident de sÃ©curitÃ©)
3. ğŸ“ **< 2h** : Documenter :
   - Quelle donnÃ©e a Ã©tÃ© partagÃ©e ?
   - Quel outil (ChatGPT, Copilot, etc.) ?
   - Quand (date/heure) ?
   - Actions dÃ©jÃ  prises
4. ğŸ” **< 24h** : Suivre avec IT pour rÃ©solution

**Pas de panique** : Les erreurs arrivent. L'important est de rÃ©agir vite.

### Process de signalement IT

```
Incident dÃ©tectÃ©
      â†“
Ouvrir ticket IT (PrioritÃ©: Security)
      â†“
IT Ã©value l'impact
      â†“
   â”Œâ”€â”€â”´â”€â”€â”
   â”‚     â”‚
Faible  Ã‰levÃ©
   â”‚     â”‚
   â†“     â†“
24-48h  ImmÃ©diat
```

## 6. Formation continue

### Ressources recommandÃ©es

**OWASP LLM Top 10** (lecture 1h) :
- ğŸ”— [https://genai.owasp.org/](https://genai.owasp.org/)
- Comprendre les 10 risques principaux
- Focus sur LLM06 et LLM09

**Guides des providers** :
- ChatGPT Safety Best Practices
- GitHub Copilot Security Guidelines
- Documentation de votre outil

**Formation interne** :
- Formation IA Awareness (2h) - obligatoire
- Sessions de partage d'Ã©quipe (optionnel)

### Mise Ã  jour des connaissances

- **Trimestriel** : Relire OWASP LLM Top 10 (mises Ã  jour frÃ©quentes)
- **Annuel** : Renouveler la formation IA Awareness
- **Continu** : Suivre les annonces de votre provider (security updates)

## Checklist Secure (Employee)

### ğŸš€ Startup / Individu

- [ ] Activer MFA sur tous les comptes IA
- [ ] Utiliser un gestionnaire de mots de passe
- [ ] Lire OWASP LLM Top 10 (focus LLM06, LLM09)
- [ ] VÃ©rifier les paramÃ¨tres de confidentialitÃ© des outils
- [ ] ConnaÃ®tre le processus de signalement IT
- [ ] Appliquer la checklist avant chaque utilisation

## Prochaine Ã©tape

â†’ [Phase 6 : Manage](06-manage.md) - GÃ©rer votre productivitÃ© personnelle avec l'IA
