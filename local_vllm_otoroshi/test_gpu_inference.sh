#!/bin/bash

BLUE='\033[0;34m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}   ğŸ§ª Test d'infÃ©rence GPU avec Ollama${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

MODEL=${1:-"llama2"}

# VÃ©rifier si le modÃ¨le existe
echo -e "${YELLOW}ğŸ” VÃ©rification du modÃ¨le $MODEL...${NC}"
if ! docker exec ollama ollama list | grep -q "$MODEL"; then
    echo -e "${YELLOW}âš ï¸  ModÃ¨le $MODEL non trouvÃ©. TÃ©lÃ©chargement...${NC}"
    docker exec ollama ollama pull "$MODEL"
    if [ $? -ne 0 ]; then
        echo -e "${RED}âœ— Ã‰chec du tÃ©lÃ©chargement${NC}"
        exit 1
    fi
fi
echo -e "${GREEN}âœ… ModÃ¨le prÃªt${NC}"
echo ""

# Afficher les logs Ollama en arriÃ¨re-plan
echo -e "${YELLOW}ğŸ“‹ Surveillance des logs Ollama...${NC}"
docker logs ollama -f 2>&1 | grep -i "gpu\|rocm\|hip\|cuda\|vram\|loading" &
LOG_PID=$!

sleep 2
echo ""

# Faire une requÃªte de test
echo -e "${YELLOW}ğŸš€ ExÃ©cution d'une requÃªte de test...${NC}"
echo ""

START_TIME=$(date +%s)

RESPONSE=$(curl -s \
    -H 'Otoroshi-Client-Id: my-llm-client-id' \
    -H 'Otoroshi-Client-Secret: my-llm-client-secret' \
    -H 'Host: ollama.oto.tools' \
    -H 'Content-Type: application/json' \
    -d "{
        \"model\": \"$MODEL\",
        \"messages\": [{\"role\": \"user\", \"content\": \"Say hello in one short sentence.\"}],
        \"stream\": false
    }" \
    http://localhost:8080/v1/chat/completions)

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

# ArrÃªter la surveillance des logs
kill $LOG_PID 2>/dev/null

echo ""
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}   ğŸ“Š RÃ©sultats${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

if echo "$RESPONSE" | jq -e '.choices[0].message.content' > /dev/null 2>&1; then
    echo -e "${GREEN}âœ… RequÃªte rÃ©ussie${NC}"
    echo ""
    echo "RÃ©ponse du modÃ¨le:"
    echo "$RESPONSE" | jq -r '.choices[0].message.content'
    echo ""
    echo "DurÃ©e: ${DURATION}s"
    echo ""
    
    # Analyser les tokens
    if echo "$RESPONSE" | jq -e '.usage' > /dev/null 2>&1; then
        echo "Usage:"
        echo "$RESPONSE" | jq '.usage'
    fi
else
    echo -e "${RED}âœ— Erreur lors de la requÃªte${NC}"
    echo "$RESPONSE" | jq . 2>/dev/null || echo "$RESPONSE"
fi

echo ""
echo -e "${YELLOW}ğŸ’¡ Pour surveiller l'utilisation GPU en temps rÃ©el:${NC}"
echo "  Terminal 1: watch -n 1 'docker exec ollama sh -c \"ps aux | grep ollama\"'"
echo "  Terminal 2: ./monitor_resources.sh continuous"
echo ""

# VÃ©rifier les statistiques du conteneur
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${BLUE}   ğŸ“ˆ Statistiques conteneur Ollama${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""
docker stats ollama --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"
