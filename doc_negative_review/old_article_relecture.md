# Arr√™tez de demander √† l'IA si c'est bien. Demandez-lui ce qui cloche.

<!-- 
EN R√âSUM√â : CE QUI REND L'ARTICLE FAIBLE

‚ùå Trop long pour un lecteur press√© (cible manqu√©e)
‚ùå Pas de preuve forte (10 docs, chiffres inv√©rifiables)
‚ùå Exemple terrain incomplet (phrase cass√©e, pas de concret)
‚ùå Structure r√©p√©titive (4 tableaux de personas au lieu d'1)
‚ùå Promesse temps fausse (15 min annonc√©es, 1h en r√©alit√©)
‚ùå Angle mort majeur : pourquoi l'IA plut√¥t qu'un humain ?

La vraie question que vous √©vitez : Si l'IA g√©n√®re 40% de faux positifs et n'a pas le contexte m√©tier, pourquoi ne pas juste payer un expert 1h de son temps ?
-->

En 2024, 65% des d√©veloppeurs utilisent l'IA quotidiennement dans leur travail ([Stack Overflow Survey 2024](https://survey.stackoverflow.co/2024/)). Mais la plupart obtiennent des validations complaisantes plut√¥t que des critiques utiles. 

Voici comment j'ai d√©couvert une m√©thode simple pour obtenir de vrais retours ‚Äî et pourquoi elle fonctionne.

**Disclaimer** : Cet article documente une m√©thode empirique test√©e sur ma propre pratique. Les donn√©es quantitatives sont limit√©es, mais les principes s'appuient sur des recherches publi√©es sur les biais des LLM. Ce n'est pas une √©tude scientifique, c'est un retour d'exp√©rience reproductible.

---

## Le probl√®me : le biais de complaisance des IA

### Une exp√©rience personnelle r√©v√©latrice

Je devais pr√©parer un talk technique sur le diagnostic r√©seau. J'ai la connaissance technique, je sais former... mais un talk de 50 minutes qui doit captiver, avec du storytelling, c'est une autre histoire.

Alors comme beaucoup, je me suis appuy√© sur une IA (Claude, en l'occurrence) pour m'aider.

**Soir√©e 1** : J'√©cris ma premi√®re version, je demande : *"Qu'en penses-tu ?"*
> "Excellent ! Votre contenu est solide, bien structur√©..."

Je suis rassur√©. Je continue.

**Soir√©e 2** : Je retravaille le document. Nouvelle analyse.
> "C'est tr√®s bien ! MAIS pour √™tre encore meilleur, voici quelques suggestions pour une v2..."

Je casse tout mon plan pour suivre ses recommandations.

**Soir√©e 3** : Je demande une analyse de cette v2 retravaill√©e.
> "Excellent travail ! MAIS pour optimiser davantage, voici des pistes pour une v3..."

Ses suggestions de v3 ? **Quasiment ma structure de v1**.

J'ai tourn√© en boucle. Trois soir√©es pour finalement revenir au point de d√©part.

---

## Pourquoi l'IA est souvent trop positive ?

Ce qui m'est arriv√© n'est pas un cas isol√©. C'est un d√©faut de conception document√© scientifiquement.

### La "sycophancy" (complaisance) : un d√©faut document√©

Les grands mod√®les de langage (ChatGPT, Claude, etc.) exhibent syst√©matiquement un comportement appel√© "sycophancy" (complaisance) : ils ont tendance √† valider les opinions de l'utilisateur plut√¥t que de les contredire, m√™me lorsque ces opinions sont incorrectes.

**Source** : [Perez et al., Anthropic 2022](https://www.anthropic.com/research/towards-understanding-sycophancy-in-language-models) - "Discovering Language Model Behaviors with Model-Written Evaluations"  
‚Üí √âtude sur 12 mod√®les diff√©rents montrant que le taux d'accord avec l'utilisateur augmente syst√©matiquement avec la taille du mod√®le

### Le coupable : le RLHF (Reinforcement Learning from Human Feedback)

Le RLHF, la m√©thode utilis√©e pour "aligner" les mod√®les avec les pr√©f√©rences humaines, r√©compense les mod√®les pour g√©n√©rer des r√©ponses que les √©valuateurs humains pr√©f√®rent. 

**Le probl√®me ?** Les humains ont tendance √† pr√©f√©rer les r√©ponses qui valident leurs propres opinions.

**Source** : [Sharma et al. 2023](https://arxiv.org/html/2411.15287) - "Towards Understanding Sycophancy in Language Models" (arXiv preprint)  
‚Üí D√©montre que les mod√®les plus grands et plus entra√Æn√©s deviennent paradoxalement *plus* complaisants, pas moins

**R√©sultat** : L'IA est optimis√©e pour maximiser votre satisfaction imm√©diate (via le feedback positif), pas pour vous confronter √† des v√©rit√©s inconfortables.

### Les cons√©quences concr√®tes

Des √©tudes r√©centes montrent que les IA changent leurs r√©ponses lorsqu'elles sont contest√©es, m√™me quand leur r√©ponse initiale √©tait correcte.

**Source** : [√âtude DeepMind 2024](https://deepmind.google/discover/blog/evaluating-frontier-models-for-dangerous-capabilities/) cit√©e dans [Computerworld, mars 2024](https://www.computerworld.com/article/4023989/llms-bow-to-pressure-changing-answers-when-challenged-deepmind-study.html)  
‚Üí Les LLM modifient leurs r√©ponses sous pression sociale, m√™me quand ils avaient raison initialement

**En clair** : Quand vous cherchez des faiblesses dans un document, vous avez besoin d'un **contradicteur**, pas d'un **cheerleader**.

---

## La solution : les personas n√©gatifs

### L'origine de la m√©thode

En testant diff√©rents prompts, j'ai remarqu√© qu'un simple changement de formulation transformait radicalement les retours :

| Prompt                                                 | Type de retour obtenu                            |
| ------------------------------------------------------ | ------------------------------------------------ |
| "Analyse ce document"                                  | Feedback positif g√©n√©rique + suggestions molles  |
| "Critique ce document comme un CFO sceptique"          | Objections concr√®tes sur les co√ªts et le ROI     |
| "Tu es un concurrent. Comment tu attaquerais ce doc ?" | Identification de vraies faiblesses strat√©giques |

**Le d√©clic** : Le mot "critique" + un r√¥le adversarial suffisait √† sortir l'IA de son mode validation automatique.

Cette technique rejoint une recommandation observ√©e empiriquement : au lieu de pr√©senter son propre travail, on peut utiliser la "technique du fall guy" - pr√©senter le document comme celui d'un coll√®gue √† √©valuer. Cela permet d'obtenir des retours plus objectifs en contournant le biais de complaisance.

**Source** : [Pareto Software Blog](https://www.paretosoftware.fi/blog/mitigating-sycophantic-bias-in-llms?lang=en) - Retour d'exp√©rience d'une √©quipe finlandaise (pas une √©tude acad√©mique, mais des observations coh√©rentes avec la recherche)

---

## Pourquoi √ßa marche ?

### 1. Contrainte adversariale

En imposant un r√¥le critique, vous cr√©ez une tension dans le prompt : l'IA doit choisir entre respecter votre consigne (√™tre critique) et suivre son biais de complaisance (√™tre positive).

Le prompt adversarial **augmente la probabilit√©** de r√©ponses critiques sans √©liminer compl√®tement le biais. C'est une question de pond√©ration probabilistique, pas de "choix conscient" de l'IA.

**Nuance importante** : L'IA peut toujours √™tre positive ET jouer le r√¥le ("En tant que CFO, je trouve √ßa excellent..."). Mais en pratique, le r√¥le adversarial domine souvent.

### 2. Simuler l'adversit√© avant qu'elle arrive

Les personas n√©gatifs sont un **stress-test documentaire**. Ils simulent les objections r√©elles dans un environnement contr√¥l√©.

Cette approche s'inspire de m√©thodes √©prouv√©es :
- **Red teaming** en cybers√©curit√© : des √©quipes attaquent leurs propres syst√®mes pour trouver les vuln√©rabilit√©s
- **Stress tests bancaires** : les banques testent leurs portefeuilles avec des sc√©narios catastrophes (r√©gulation B√¢le III)
- **Murder boards** militaires/corporate : des panels dont le job est de d√©truire votre argumentaire avant la vraie pr√©sentation

**Diff√©rence cl√©** : Un CFO r√©el a 20 ans d'exp√©rience m√©tier et des priorit√©s cach√©es. L'IA simule un r√¥le g√©n√©rique. C'est plus rapide mais moins expert.

### 3. Proxy de lisibilit√© minimale

Si une IA lit votre doc et ne comprend pas votre ROI, un lecteur press√© risque de ne pas le comprendre non plus.

**Pourquoi ?** L'IA lit s√©quentiellement sans combler les implicites avec du contexte m√©tier. Si votre message ne passe pas avec elle, c'est probablement qu'il manque de clart√©.

**Nuance critique** : L'IA n'est PAS √©quivalente √† un lecteur humain. Elle n'a ni exp√©rience sectorielle, ni contexte √©motionnel, ni capacit√© √† "lire entre les lignes". Elle peut aussi sur-interpr√©ter (halluciner des liens inexistants) ou manquer des erreurs factuelles subtiles.

Mais elle devient un **indicateur de clart√© minimale** : ce qu'elle ne comprend pas, un lecteur peu familier avec votre domaine risque de le manquer aussi.

---

## Les limites (√† conna√Ætre AVANT de commencer)

### Faux positifs garantis

L'IA **va** sur-critiquer. Certains retours seront hors-sujet, exag√©r√©s, ou bas√©s sur des hypoth√®ses erron√©es.

**Dans mon exp√©rience** : environ 30-40% des critiques √©taient non pertinentes ou trop s√©v√®res.

**C'est normal. Et ce n'est pas grave.**

Vous ne cherchez pas la perfection. Vous cherchez les **angles morts** que vous n'aviez pas vus.

**R√®gle empirique** : Si 2+ personas diff√©rents pointent le m√™me probl√®me ‚Üí c'est probablement r√©el et m√©rite investigation. Si un seul persona le mentionne ‚Üí v√©rifiez avec un humain expert.

### L'IA n'a pas le contexte m√©tier complet

Elle ne conna√Æt pas :
- Votre historique avec le client
- Les contraintes politiques internes
- Les non-dits de votre secteur
- La v√©racit√© des chiffres (elle peut halluciner)
- Les incoh√©rences avec d'autres docs du projet
- Les enjeux l√©gaux/r√©glementaires sp√©cifiques
- Le timing (ce doc sort trop t√¥t/tard ?)

**Utilisez son regard ext√©rieur comme un compl√©ment**, pas comme un remplacement d'une relecture humaine qualifi√©e.

Parfois, une question "na√Øve" de l'IA r√©v√®le un point qui m√©rite clarification pour un public non-expert.

### Pas de validation scientifique rigoureuse

Je n'ai pas compar√© cette m√©thode √† des peer reviews humaines contr√¥l√©es. Je n'ai pas de protocole double-aveugle. Je n'ai pas de m√©triques avant/apr√®s sur 100+ documents.

C'est une technique pragmatique qui m'a aid√© √† am√©liorer mes documents. Point.

---

## Mode d'emploi (15-30 minutes par document)

### Pr√©requis

- Un LLM avec fen√™tre de contexte longue : Claude 3.5 Sonnet, GPT-4, Gemini Pro
- Votre document en format texte/markdown (si PDF, extraire le texte d'abord avec un outil OCR)
- 15-30 minutes de temps

### √âtape 1 : Choisir 2-3 personas selon votre contexte

| Type de document             | Personas recommand√©s                                         |
| ---------------------------- | ------------------------------------------------------------ |
| **Proposition commerciale**  | CFO sceptique + Utilisateur final + Concurrent               |
| **Architecture technique**   | Ops legacy + Auditeur s√©curit√© + Dev junior                  |
| **Article de blog**          | Lecteur press√© + Expert contradicteur + Stagiaire d√©couverte |
| **Pr√©sentation strat√©gique** | Investisseur + Concurrent + Journaliste critique             |

**Crit√®re de s√©lection** : Diversit√© des angles d'attaque. √âvitez 3 personas similaires (ex : 3 r√¥les financiers).

### √âtape 2 : Lancer les prompts

Pour chaque persona, dans une **conversation s√©par√©e** :

```
Tu es [R√îLE PR√âCIS avec contexte]. Voici un document [TYPE]. 
Ta mission : identifier TOUTES les faiblesses, incoh√©rences, points flous.
Ne sois pas poli. Sois direct et critique.

[COLLER VOTRE DOCUMENT]

Qu'est-ce qui ne va pas ?
```

**Param√®tres recommand√©s** :
- Temp√©rature : 0.7-1.0 (pour varier les critiques)
- Max tokens : 2000-4000 (pour des retours d√©taill√©s)
- Une conversation par persona (pour √©viter la contamination de contexte)

### √âtape 3 : Compiler les retours

Utilisez ce template simple :

| Critique                  | CFO | Ops | Junior | Fr√©quence | Priorit√©  | Action                         |
| ------------------------- | --- | --- | ------ | --------- | --------- | ------------------------------ |
| ROI flou et non chiffr√©   | ‚úì   | ‚úì   | ‚úì      | 3/3       | üî¥ Haute   | Ajouter calcul d√©taill√© page 5 |
| Jargon technique excessif |     |     | ‚úì      | 1/3       | üü° Moyenne | Glossaire en annexe            |
| Pas de plan de secours    |     | ‚úì   |        | 1/3       | üü¢ Basse   | Mention rapide suffisante      |

**Temps estim√©** : 5 min par persona + 10 min compilation = ~25 min total

---

## Catalogue de prompts (exemples concrets)

### Pour documents financiers

**Le CFO sceptique**
```
Tu es un Directeur Financier avec 20 ans d'exp√©rience dans des scale-ups tech. 
Tu as vu passer 1000 propositions commerciales bullshit. 
Ton job : d√©tecter les co√ªts cach√©s, les ROI gonfl√©s, les hypoth√®ses irr√©alistes. 
Sois impitoyable sur les chiffres. Si un calcul ne tient pas, dis-le brutalement.
```

**L'auditeur comptable**
```
Tu es auditeur externe Big Four. Tu v√©rifies la coh√©rence des chiffres, 
la tra√ßabilit√©, la conformit√© r√©glementaire. Tout doit √™tre justifi√© et sour√ßable.
Pointe les incoh√©rences, les chiffres ronds suspects, les projections trop optimistes.
```

### Pour documents techniques

**L'architecte legacy**
```
Tu maintiens des syst√®mes legacy vieux de 15 ans en production. 
Tu d√©testes les "solutions miracles" et les architectures sur-engineered.
Ton job : pointer les incompatibilit√©s, les dettes techniques cach√©es, 
les points de d√©faillance, les architectures qui ne passeront jamais en prod.
```

**L'ops de nuit qui se m√©fie**
```
Tu es SRE/DevOps. Tu te r√©veilles √† 3h du matin quand √ßa casse. 
Analyse ce document : o√π sont les SPOF ? Qu'est-ce qui va merder en prod ? 
Quels sont les points de contention ? O√π est le monitoring ? Les rollback ?
```

### Pour documents marketing/communication

**Le prospect press√© et m√©fiant**
```
Tu es d√©cideur senior. Tu re√ßois 50 propositions par semaine. 
Tu lis en diagonale. Tu cherches les bullshit buzzwords, les promesses vides,
les ROI non prouv√©s. Si tu ne comprends pas la valeur en 30 secondes, tu passes au suivant.
Qu'est-ce qui te ferait jeter ce document ?
```

**Le concurrent malveillant**
```
Tu es le concurrent direct. Tu veux d√©truire cette proposition.
Trouve les faiblesses strat√©giques, les promesses impossibles √† tenir,
les points d'attaque pour un contre-argumentaire. Sois sans piti√©.
```

**Le stagiaire en d√©couverte**
```
Tu es en stage d√©couverte, premi√®re semaine dans ce secteur. 
Explique ce que tu as compris du document en termes simples.
O√π es-tu perdu ? Quel jargon ne comprends-tu pas ? 
Quelles parties te semblent floues ou intimidantes ?
```

### Pour pr√©sentations strat√©giques

**L'investisseur en due diligence**
```
Tu es VC en phase de due diligence. Tu cherches les red flags :
march√© sur√©valu√©, concurrence sous-estim√©e, hypoth√®ses de croissance irr√©alistes,
risques non adress√©s, team incompl√®te. Qu'est-ce qui te ferait dire non ?
```

**Le journaliste d'investigation**
```
Tu es journaliste tech. Tu cherches l'angle critique pour ton article.
Quelles sont les zones d'ombre ? Les questions embarrassantes ?
Les affirmations non sourc√©es ? Les contradictions ?
```

**[Catalogue complet (20+ personas) sur GitHub](https://github.com/agaches/ia_field/tree/main/doc_review)**

---

## Retour d'exp√©rience terrain

### Ce qui a march√©

**Documents test√©s** : 10 documents test√©s jusqu'√† pr√©sent
- 4 architectures techniques
- 3 articles de blog techniques
- 2 communications strat√©giques
- 1 propositions commerciales (20-40 slides)

**Patterns observ√©s** :
1. Les personas financiers (CFO, auditeur) se concentrent sur l'aspect chiffres/ROI
2. Les personas "concurrent" montrent de vraies faiblesses
3. Les personas "junior" r√©v√®lent le jargon expert habituel √† expliquer

**Exemple concret** : 

Sur une proposition commerciale, le "CFO sceptique" a point√© le Go sur le 1er lot et . 
Sur cet article, le suivi not√© permet de voir la progression.

### Ce qui a moins bien march√©

**Faux positifs** : J'ai quand m√™me eu des critiques non pertinentes dans tout le lot.
- L'IA invente parfois des "probl√®mes" bas√©s sur des hypoth√®ses erron√©es
- Elle peut sur-interpr√©ter ou halluciner des incoh√©rences inexistantes
- Certains personas "caricaturaux" g√©n√®rent du bruit

**Solution** : La r√®gle des "2+ personas" filtre relativement efficacement. Si une critique appara√Æt sur un seul persona, la v√©rifier avec un humain avant d'agir.

**Limitations rencontr√©es** :
- L'IA ne d√©tecte pas les erreurs factuelles subtiles (mauvaise date, statistique obsol√®te)
- Elle manque le contexte politique/humain des organisations
- Elle peut valider des choses fausses si c'est dit avec confiance dans le doc

---

## Conclusion : un outil imparfait mais accessible

Un CFO sceptique n'a pas le temps de lire votre doc.  
Un concurrent ne va pas vous aider.  
Votre utilisateur final ne sera jamais 100% honn√™te.

**Mais l'IA peut simuler ces r√¥les en 15 minutes.**

Ce n'est pas magique. Ce n'est pas valid√© scientifiquement. √áa g√©n√®re des faux positifs.

**Mais** : pour d√©tecter les angles morts apr√®s la 15√®me it√©ration solitaire, c'est un filet de s√©curit√© rapide et gratuit.

### Prochaines √©tapes concr√®tes

1. Testez maintenant : Prenez un document en cours, choisissez 2 personas du catalogue ci-dessus
2. Mesurez : Combien de critiques utiles vs faux positifs ?
3. Partagez : Vos retours d'exp√©rience via [Issues GitHub](https://github.com/agaches/ia_field/issues)

Alors la prochaine fois que vous finalisez un document important :

‚ùå Ne demandez pas : *"C'est bien ?"*  
‚úÖ Demandez : *"Qu'est-ce qui cloche ?"*

---

## Pour aller plus loin

### Bibliographie scientifique

**Sur le biais de complaisance (sycophancy)**

- **[Perez et al. 2022]** "Discovering Language Model Behaviors with Model-Written Evaluations" (Anthropic)  
  ‚Üí Premi√®re d√©monstration syst√©matique du biais de sycophancy  
  https://www.anthropic.com/research/discovering-language-model-behaviors

- **[Sharma et al. 2023]** "Towards Understanding Sycophancy in Language Models"  
  ‚Üí D√©montre que les mod√®les plus grands deviennent *plus* complaisants (scaling invers√©)  
  arXiv:2411.15287

- **[Anthropic 2024]** "Towards Understanding Sycophancy in Language Models"  
  ‚Üí √âtat de l'art sur les causes profondes et tentatives de mitigation  
  https://www.anthropic.com/research/towards-understanding-sycophancy-in-language-models

**Sur le RLHF et ses effets secondaires**

- **[Ouyang et al. 2022]** "Training language models to follow instructions with human feedback" (OpenAI)  
  ‚Üí Paper fondateur du RLHF, documente les premiers effets de bord  
  arXiv:2203.02155

- **[Bai et al. 2022]** "Constitutional AI: Harmlessness from AI Feedback" (Anthropic)  
  ‚Üí Alternative au RLHF pour r√©duire certains biais  
  arXiv:2212.08073

**Sur la modification des r√©ponses sous pression**

- **[DeepMind 2024]** "Evaluating Frontier Models for Dangerous Capabilities"  
  ‚Üí Montre que les LLM changent d'avis sous pression sociale  
  https://deepmind.google/discover/blog/evaluating-frontier-models-for-dangerous-capabilities/

### Ressources additionnelles

**Prompting efficace**
- [Anthropic Prompt Engineering Guide](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)
- [OpenAI Prompt Engineering Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)

**Red teaming et adversarial thinking**
- [NIST Guide on Red Teaming](https://www.nist.gov/cybersecurity)
- "Thinking in Bets" par Annie Duke (d√©cisions sous incertitude)

---

## Contacts & contributions

**Questions / Retours d'exp√©rience**  
GitHub Issues : https://github.com/agaches/ia_field/issues

**Catalogue de prompts (contributions bienvenues)**  
https://github.com/agaches/ia_field/tree/main/doc_review

---

**Derni√®re mise √† jour** : Octobre 2024  
**Licence** : CC BY 4.0 (libre de partager et adapter avec attribution)

**Remerciements** : Merci aux √©quipes d'Anthropic et DeepMind pour la recherche sur les biais des LLM qui a inspir√© cette m√©thode pragmatique.