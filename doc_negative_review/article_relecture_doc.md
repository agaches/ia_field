# Arr√™tez de demander au LLM si c'est bien. Demandez-lui ce qui cloche.

## Introduction : La boucle de l'enfer

Il y a quelques mois, pour un talk technique, j'ai demand√© √† Claude : *"Qu'en penses-tu ?"*

*   V1 : *"Excellent ! Solide."*
*   V2 (apr√®s retouches) : *"G√©nial ! Mais inverse A et B, et rajoutes C."*
*   V3 (apr√®s modifs) : *"Parfait ! Pour am√©liorer la fluidit√©, inverser B et A. Et C ne sert √† rien."*

J'ai compris ce soir-l√† que l'IA pr√©f√©rait me r√©pondre positivement plut√¥t que de me dire ce qui clochait. Ce comportement de "Yes Man" n'est pas un bug, c'est un d√©faut de conception document√©.

## Le probl√®me : le biais de complaisance des LLM

### La "sycophancy" (complaisance) : un d√©faut document√©

Les grands mod√®les de langage (ChatGPT, Claude, Gemini, etc.) montrent syst√©matiquement un comportement appel√© "sycophancy" (complaisance) : ils ont tendance √† valider les opinions de l'utilisateur plut√¥t que de les contredire, m√™me lorsque ces opinions sont incorrectes [1].

### Le coupable : le r√©entra√Ænement (Reinforcement Learning from Human Feedback - RLHF)

Le r√©entra√Ænement des mod√®les (RLHF) favorise les r√©ponses qui plaisent aux √©valuateurs humains plut√¥t que la v√©rit√© objective. Paradoxalement, plus un mod√®le est grand et entra√Æn√©, plus il devient complaisant [2].

**R√©sultat** : Le mod√®le est optimis√© pour votre satisfaction imm√©diate, pas pour la v√©rit√©.

### Les cons√©quences concr√®tes critiques

Des √©tudes r√©centes montrent que les LLM changent leurs r√©ponses lorsqu'elles sont contest√©es, m√™me quand leur r√©ponse initiale √©tait correcte.

Concr√®tement, une simple remise en question (ex: "T'es s√ªr ?") peut pousser le LLM √† changer sa r√©ponse par pression sociale, validant l'utilisateur au d√©triment de la v√©rit√© [3].

## La solution : les personas n√©gatifs

Le changement de formulation transforme radicalement les retours :

| Prompt                                                 | Type de retour obtenu                           |
| ------------------------------------------------------ | ----------------------------------------------- |
| "Analyse ce document"                                  | Feedback positif g√©n√©rique + suggestions molles |
| "Critique ce document"                                 | Critiques ouvertes du document                  |
| "Tu es un concurrent. Comment tu attaquerais ce doc ?" | Identification de vraies faiblesses             |

> **Astuce** : Pr√©cisez au mod√®le que ce document n'est pas le v√¥tre (ex: "J'ai re√ßu ce brouillon d'un coll√®gue..."). Cela d√©sactive le filtre de politesse du mod√®le qui cherche √† ne pas vous vexer.

## Pourquoi √ßa marche ?

### Contrainte de l'adversaire

En imposant un r√¥le critique, vous cr√©ez une tension dans le prompt : l'IA doit choisir entre respecter votre consigne (√™tre critique) et suivre son biais de complaisance (√™tre positive).

Le prompt adversarial **augmente la probabilit√©** de r√©ponses critiques sans √©liminer compl√®tement le biais.

### Simuler l'adversit√© avant qu'elle arrive

Les personas n√©gatifs sont un **stress-test documentaire**. Ils simulent les objections r√©elles dans un environnement contr√¥l√©.

Cette approche s'inspire de m√©thodes √©prouv√©es :
- **Red teaming** en cybers√©curit√© : des √©quipes attaquent leurs propres syst√®mes pour trouver les vuln√©rabilit√©s
- **Stress tests bancaires** : les banques testent leurs portefeuilles avec des sc√©narios catastrophes (r√©gulation B√¢le III)
- **Murder boards** militaires/corporate : des panels dont le job est de d√©truire votre argumentaire avant la vraie pr√©sentation

### Remplacement d'un lecteur externe

Si un LLM lit votre doc et ne comprend pas vos propos, un lecteur press√© risque de ne pas le comprendre non plus.

Par ce test, elle devient un **indicateur de complexit√©** en identifiant le langage sp√©cifique √† votre domaine qu'elle ne maitrise pas (et que donc un lecteur externe ne maitrise pas non plus).

## Limites et bonnes pratiques

### 1. Faux positifs : la r√®gle des "2+ personas"
Le LLM peut inventer des probl√®mes pour satisfaire la consigne. 
**R√®gle** : Si **2+ personas** pointent le m√™me probl√®me ‚Üí c'est probablement r√©el. Sinon, v√©rifiez.

### 2. Manque de contexte
Avec un contexte vide, le LLM ignore le contexte et l'historique interne de votre entreprise. 
Utilisez sa "na√Øvet√©" comme un atout : c'est un test d'accessibilit√© pour un lecteur externe.

### 3. Diversifier les angles de vue
Pour un r√©sultat optimal, **m√©langez les retours** : combinez des critiques sur la forme (√©criture, coh√©sion) et sur le fond (logique, pertinence strat√©gique).

## Next step : Passez √† l'offensive

Tant que vous chercherez la validation dans vos prompts, vous obtiendrez de la complaisance.
Pour transformer vos documents, vous devez changer vos prompts.

### Votre bo√Æte √† outils pour commencer

Pour vous √©viter de partir d'une page blanche, j'ai compil√© et test√© une s√©rie de "Personas N√©gatifs" pr√™ts √† l'emploi. Ce catalogue √† faire √©voluer contient des prompts pour :
*   Simuler un **CFO** obs√©d√© par le ROI.
*   Incarner un **Concurrent** agressif.
*   Jouer le r√¥le d'un **Lecteur press√©** qui d√©croche au moindre flou.

üëâ **[Acc√©der au Catalogue de Prompts N√©gatifs](https://github.com/agaches/ia_field/blob/main/doc_review/catalogue_negative_prompts.md)**

### Mode d'emploi express (15 min chrono)

Voici comment je proc√®de :
1.  **Choisissez 2 Personas oppos√©s** (ex: un CFO pour les chiffres + un Concurrent pour la strat√©gie).
2.  **Ouvrez une conversation vierge** pour chaque persona (pour √©viter la contamination du contexte).
3.  **Copiez-collez le prompt + votre texte**.
4.  **Compilez uniquement les critiques qui reviennent 2 fois**. Le reste, c'est du bruit.

### La preuve par l'exemple : le crash-test de cet article

Pour ne pas reproduire l'erreur de mon talk r√©seau, j'ai appliqu√© cette m√©thode sur l'article que vous lisez. Je suis parti d'un premier brouillon bavard (consultable ici : [l'article original avant critique](old_article_relecture.md)) et je l'ai fait passer √† la moulinette de 3 prompts it√©ratifs.

**1. Le prompt "Valeur" (pour √©laguer)**
> *"Identifie dans ce document :
1. Les paragraphes qui n'apportent pas de valeur (pure rh√©torique)
2. Les sections qui manquent de substance
3. Le ratio contenu utile / remplissage
4. Les zones o√π l'on pourrait √™tre plus concis
Fournis un % de contenu "utile" vs "remplissage" pour chaque section."*

**2. Le prompt "Coh√©rence" (pour structurer)**
> *"Analyse ce document en v√©rifiant :
La coh√©rence logique du d√©but √† la fin
Les √©ventuelles contradictions entre sections
Les ruptures dans le fil narratif
Les redondances inutiles"*

**3. Le prompt "Qualit√© per√ßue" (pour cr√©dibiliser)**
> *"Tu es un lecteur qui sature des articles putaclic et des machins g√©n√©r√©s par IA.
√âvalue :
La rigueur de l'argumentation (1-10)
La qualit√© des sources et r√©f√©rences (1-10)
Le professionnalisme du ton (1-10)
La pr√©cision des donn√©es (1-10)
Qu'est-ce qui te fait penser "article de qualit√©" vs "article bof" "*

**4. Le prompt "Journaliste exp√©riment√©" (pour finaliser)**
> *"Tu es un journaliste exp√©riment√©.
La personne est un amateur qui appr√©cie un style simple, direct, concret, qui parle un peu de lui et avec un peu d'humour.
Reprends une analyse en profondeur de l'article en r√©sultat et donnes-en un avis."*

Les scores avant/apr√®s :
*   **Ratio % utile :** Pass√©e globalement de 60% √† 96%
*   **Qualit√© per√ßue :** Note pass√©e de 4/10 (argumentaire mou) √† 9/10 (logique implacable).

**L'exemple le plus parlant ? L'introduction.**
La version brouillon s'√©talait sur **12 lignes** de narration personnelle ("Je devais pr√©parer un talk... J'ai la connaissance technique...").
La version finale tient en **6 lignes** qui posent le conflit imm√©diatement sans trop rentrer dans le d√©tail.

Le lien vers la premi√®re version pour la comparaison :
üëâ **[Acc√©der √† l'ancien article](https://github.com/agaches/ia_field/blob/main/doc_review/old_article_relecture.md.md)**

L'**Avis final du journaliste:** C'est un article solide, utile et agr√©able √† lire. Il ne cherche pas √† impressionner par la complexit√©, mais √† convaincre par l'efficacit√©.

## Le mot de la fin

Ne me croyez pas sur parole, essayez. 
Prenez votre dernier brouillon, et testez divers prompts (m√™me au hasard).
Essayez le  prompt du "CFO Sceptique" sur vos propositions commerciales
Essayez le prompt du "Le Bullshit Detector" sur les derni√®res communications sur l'IA
Regardez votre texte se faire d√©molir... avec tous les axes identifi√©s pour pouvoir mieux le reconstruire.

Merci d'avoir lu jusqu'ici. Et j'en profite pour remercier tous mes relecteurs et relectrices.

## Sources

[1] [Perez et al., Anthropic 2022](https://www.anthropic.com/research/towards-understanding-sycophancy-in-language-models) - "Discovering Language Model Behaviors with Model-Written Evaluations". √âtude sur 12 mod√®les diff√©rents montrant que le taux d'accord avec l'utilisateur augmente syst√©matiquement avec la taille du mod√®le. 
[2] [Malmqvist 2024](https://arxiv.org/html/2411.15287) - "Sycophancy in Large Language Models: Causes and Mitigations". Revue technique analysant les causes, les impacts et les strat√©gies d'att√©nuation de la complaisance dans les LLM.
[3] [√âtude DeepMind 2024](https://deepmind.google/discover/blog/evaluating-frontier-models-for-dangerous-capabilities/) cit√©e dans [Computerworld, mars 2024](https://www.computerworld.com/article/4023989/llms-bow-to-pressure-changing-answers-when-challenged-deepmind-study.html). Les LLM modifient leurs r√©ponses sous pression sociale, m√™me quand ils avaient raison initialement. 
